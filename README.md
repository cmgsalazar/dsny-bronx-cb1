# Department of Sanitation data 

This repository contains Department of Sanitation (DSNY) datasets from [NYC Open Data](https://opendata.cityofnewyork.us/), which I analyzed in relation to the Melrose, Mott Haven, and Port Morris neighborhoods in the South Bronx (Bronx Community District 1).

Resulting data was used in [my report for the *Mott Haven Herald*](https://motthavenherald.com/2024/10/10/bid-wants-more-cameras-in-the-hub-to-curb-illegal-dumping/). The story is also [republished in my portfolio](https://cmgsalazar.github.io/newmarkj/illegal-dumping/), with additional photos and previously unutilized interactive graph.


### Data sources

* <del>[DSNY 311 service requests from 2010 to present](https://data.cityofnewyork.us/Social-Services/Department-of-Sanitation/6xum-vkqn/about_data) *(data last updated 20 September 2024; accessed 22 September 2024)*</del> â€” The data looked outdated because only three of the over 3,000 rows were updated after 2020. The rest were dated 2012.
* [311 service requests from 2010 to present](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9/explore/query/SELECT%0A%20%20%60unique_key%60%2C%0A%20%20%60created_date%60%2C%0A%20%20%60closed_date%60%2C%0A%20%20%60agency%60%2C%0A%20%20%60agency_name%60%2C%0A%20%20%60complaint_type%60%2C%0A%20%20%60descriptor%60%2C%0A%20%20%60location_type%60%2C%0A%20%20%60incident_zip%60%2C%0A%20%20%60incident_address%60%2C%0A%20%20%60street_name%60%2C%0A%20%20%60cross_street_1%60%2C%0A%20%20%60cross_street_2%60%2C%0A%20%20%60intersection_street_1%60%2C%0A%20%20%60intersection_street_2%60%2C%0A%20%20%60address_type%60%2C%0A%20%20%60city%60%2C%0A%20%20%60landmark%60%2C%0A%20%20%60facility_type%60%2C%0A%20%20%60status%60%2C%0A%20%20%60due_date%60%2C%0A%20%20%60resolution_description%60%2C%0A%20%20%60resolution_action_updated_date%60%2C%0A%20%20%60community_board%60%2C%0A%20%20%60bbl%60%2C%0A%20%20%60borough%60%2C%0A%20%20%60x_coordinate_state_plane%60%2C%0A%20%20%60y_coordinate_state_plane%60%2C%0A%20%20%60open_data_channel_type%60%2C%0A%20%20%60park_facility_name%60%2C%0A%20%20%60park_borough%60%2C%0A%20%20%60vehicle_type%60%2C%0A%20%20%60taxi_company_borough%60%2C%0A%20%20%60taxi_pick_up_location%60%2C%0A%20%20%60bridge_highway_name%60%2C%0A%20%20%60bridge_highway_direction%60%2C%0A%20%20%60road_ramp%60%2C%0A%20%20%60bridge_highway_segment%60%2C%0A%20%20%60latitude%60%2C%0A%20%20%60longitude%60%2C%0A%20%20%60location%60%0AWHERE%0A%20%20caseless_one_of%28%60community_board%60%2C%20%2201%20BRONX%22%29%0A%20%20AND%20caseless_one_of%28%60agency_name%60%2C%20%22Department%20of%20Sanitation%22%29%0AORDER%20BY%20%60created_date%60%20DESC%20NULL%20FIRST/page/filter), filtered to show only "Department of Sanitation" in `Agency Name` and "01 Bronx" for `Community Board`. *(data last updated 30 September 2024; accessed 1 October 2024)*
* [DSNY monthly collection tonnages](https://data.cityofnewyork.us/City-Government/DSNY-Monthly-Tonnage-Data/ebb7-mvp5/about_data) *(data last updated 8 September 2024; accessed 22 September 2024)*
* [DSNY frequency boundaries for collection operation](https://data.cityofnewyork.us/City-Government/DSNY-Frequencies/rv63-53db/about_data) *(data last updated 10 April 2024; accessed 22 September 2024)*
* [DSNY litter basket map](https://data.cityofnewyork.us/dataset/DSNY-Litter-Basket-Map-/d6m8-cwh9) *(data last updated 10 April 2024; accessed 22 September 2024)*

### Analysis

I filtered the data by year, then sum values by complaint type. The initial version of my analysis only worked with the pandemic years (from 2020 to 2024), but I thought I might see more comprehensive trends if I use all the years recorded in the main dataset. 

I created functions to dynamically create new dataframes by year. To visualize the data, I attempted to use `seaborn` for a ridgeline plot, then decided against it. The data had many `NaN` which affected the accuracy of the viz I had in mind. 

The spreadsheet `parsed-data/311-complaints-by-year-CLEAN.csv` is a product of manually sanitizing the data to merge complaint type duplicates and sum values if needed. Much of this work is based on editorial preference, and I thought it would be faster to do this manually than fuzzy-match programmatically. 